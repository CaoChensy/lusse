models:
    Qwen/Qwen2.5-0.5B-Instruct:
        model: /home/models/Qwen/Qwen2.5-0.5B-Instruct
        gpu_memory_utilization: 0.05
        max_num_seqs: 2
        max_model_len: 1024
        max_num_batched_tokens: 8192
        tensor_parallel_size: 1
        enforce_eager: true
        # tool call
        enable-auto-tool-choice: true
        tool-call-parser: hermes

    Qwen/Qwen2.5-1.5B-Instruct:
        model: /home/models/Qwen/Qwen2.5-1.5B-Instruct
        gpu_memory_utilization: 0.05
        max_num_seqs: 2
        max_model_len: 1024
        max_num_batched_tokens: 8192

    Qwen/Qwen2.5-3B-Instruct:
        model: /home/models/Qwen/Qwen2.5-3B-Instruct
        gpu_memory_utilization: 0.05
        max_num_seqs: 2
        max_model_len: 1024
        max_num_batched_tokens: 8192

    Qwen/Qwen2.5-7B-Instruct:
        model: /home/models/Qwen/Qwen2.5-7B-Instruct
        gpu_memory_utilization: 0.05
        max_num_seqs: 2
        max_model_len: 1024
        max_num_batched_tokens: 8192

    Qwen/Qwen2.5-14B-Instruct:
        model: /home/models/Qwen/Qwen2.5-14B-Instruct
        gpu_memory_utilization: 0.05
        max_num_seqs: 2
        max_model_len: 1024
        max_num_batched_tokens: 8192

    eepSeek-R1-Distill-Qwen-7B:
        model: /home/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
        gpu_memory_utilization: 0.05
        max_num_seqs: 2
        max_model_len: 1024
        max_num_batched_tokens: 8192

    DeepSeek-R1-Distill-Qwen-14B:
        model: /home/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B
        gpu_memory_utilization: 0.05
        max_num_seqs: 2
        max_model_len: 1024
        max_num_batched_tokens: 8192

    Qwen2.5-32B-Instruct:
        model: /home/models/Qwen/Qwen2.5-32B-Instruct

    Qwen2.5-72B-Instruct:
        model: /home/models/Qwen/Qwen2.5-72B-Instruct

    Qwen2.5-Coder-1.5B-Instruct:
        model: /home/models/Qwen/Qwen2.5-Coder-1.5B-Instruct

    Qwen2.5-Coder-7B-Instruct:
        model: /home/models/Qwen/Qwen2.5-Coder-7B-Instruct

    Qwen2.5-VL-7B-Instruct:
        model: /home/models/Qwen/Qwen2.5-VL-7B-Instruct

    glm-4-9b-chat:
        model: /home/models/THUDM/glm-4-9b-chat

    glm-4-9b-chat-1m:
        model: /home/models/THUDM/glm-4-9b-chat-1m

    glm-4v-9b:
        model: /home/models/THUDM/glm-4v-9b

    LongWriter-glm4-9b:
        model: /home/models/THUDM/LongWriter-glm4-9b

    LongWriter-llama3.1-8b:
        model: /home/models/THUDM/LongWriter-llama3.1-8b

    LongCite-llama3.1-8b:
        model: /home/models/THUDM/LongCite-llama3.1-8b

    LongCite-glm4-9b:
        model: /home/models/THUDM/LongCite-glm4-9b

    codegeex4-all-9b:
        model: /home/models/THUDM/codegeex4-all-9b

    MiniCPM-V-2_6:
        model: /home/models/openbmb/MiniCPM-V-2_6

    MiniCPM3-4B:
        model: /home/models/openbmb/MiniCPM3-4B

    DeepSeek-V2-Lite-Chat:
        model: /home/models/deepseek-ai/DeepSeek-V2-Lite-Chat

    DeepSeek-Coder-V2-Lite-Instruct:
        model: /home/models/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct

    bge-m3:
        model: /home/models/BAAI/bge-m3

    jinaai/jina-embeddings-v3:
        model: /home/models/jinaai/jina-embeddings-v3
